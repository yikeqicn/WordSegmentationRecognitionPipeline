{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages and Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: old comet version (1.0.44) detected. current: 1.0.56 please update your comet lib with command: `pip install --no-cache-dir --upgrade comet_ml`\n",
      "COMET WARNING: Failing to collect the installed os packages\n",
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/yikeqicn/ocr-pipeline/51ff96c3b41b4bce8c58a323808a079d\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# experiment (optional)\n",
    "from comet_ml import Experiment\n",
    "experiment = Experiment(api_key=\"YkPEmantOag1R1VOJmXz11hmt\", parse_args=False, project_name='ocr_pipeline')\n",
    "experiment.set_name('pipeline_cv_east_handwriten_long_crop_merged')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import time\n",
    "import cv2\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from glob import glob\n",
    "from os.path import join, basename, dirname\n",
    "from east.model import *\n",
    "from recognition.Model import Model, DecoderType\n",
    "from recognition.utils import log_image\n",
    "from wordsegmentation.WordSegmentation import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Public Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['-image_root', '--image_root'], dest='image_root', nargs=None, const=None, default='/root/WordSegmentationRecognitionPipeline/src/Inputs/', type=<class 'str'>, choices=None, help='path to input image root', metavar=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "#general:\n",
    "parser.add_argument(\"-debug_folder\", \"--debug_folder\", type=str,default='/root/WordSegmentationRecognitionPipeline/src/debug/',help=\"path to debug folder\")\n",
    "\n",
    "# EAST model:\n",
    "## parameter\n",
    "parser.add_argument(\"-east_w\", \"--east_width\", type=int, default=1920,help=\" east model resized image width (should be multiple of 32)\")\n",
    "parser.add_argument(\"-east_e\", \"--east_height\", type=int, default=1920,help=\"east model resized image height (should be multiple of 32)\")\n",
    "parser.add_argument(\"-mini_conf\", \"--mini_conf\", type=int, default=0.5,help=\"mini_confidence for crop\")\n",
    "\n",
    "## ckpt\n",
    "parser.add_argument(\"-east\", \"--east\", type=str,default='/root/WordSegmentationRecognitionPipeline/src/east/frozen_east_text_detection.pb',help=\"path to input EAST text detector\")\n",
    "## input image root\n",
    "parser.add_argument(\"-image_root\", \"--image_root\", type=str,default='/root/WordSegmentationRecognitionPipeline/src/Inputs/',help=\"path to input image root\")\n",
    "\n",
    "# Recognition model:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recognition Model\n",
    "# basic operations\n",
    "parser.add_argument(\"-name\", default='dense_128_32_noartifact_beamsearch_5_datasets', type=str, help=\"name of the log\")\n",
    "parser.add_argument(\"-gpu\", default='-1', type=str, help=\"gpu numbers\")\n",
    "#parser.add_argument(\"-train\", help=\"train the NN\", action=\"store_true\")\n",
    "#parser.add_argument(\"-validate\", help=\"validate the NN\", action=\"store_true\")\n",
    "parser.add_argument(\"-transfer\", action=\"store_true\")\n",
    "#actually not effective:\n",
    "parser.add_argument(\"-batchesTrained\", default=0, type=int, help='number of batches already trained (for lr schedule)') \n",
    "# beam search\n",
    "parser.add_argument(\"-beamsearch\", help=\"use beam search instead of best path decoding\",default=True, action=\"store_true\")\n",
    "parser.add_argument(\"-wordbeamsearch\", help=\"use word beam search instead of best path decoding\", action=\"store_true\")\n",
    "# training hyperparam\n",
    "parser.add_argument(\"-batchsize\", default=50, type=int, help='batch size') # actually not effective in infrerence\n",
    "parser.add_argument(\"-lrInit\", default=1e-2, type=float, help='initial learning rate') # actually not effective\n",
    "parser.add_argument(\"-optimizer\", default='rmsprop', help=\"adam, rmsprop, momentum\") # actually not effective\n",
    "parser.add_argument(\"-wdec\", default=1e-4, type=float, help='weight decay') # acctually not effective\n",
    "#parser.add_argument(\"-lrDrop1\", default=10, type=int, help='step to drop lr by 10 first time')\n",
    "#parser.add_argument(\"-lrDrop2\", default=1000, type=int, help='step to drop lr by 10 sexond time')\n",
    "#parser.add_argument(\"-epochEnd\", default=40, type=int, help='end after this many epochs')\n",
    "# trainset hyperparam\n",
    "#parser.add_argument(\"-noncustom\", help=\"noncustom (original) augmentation technique\", action=\"store_true\")\n",
    "#parser.add_argument(\"-noartifact\", help=\"dont insert artifcats\", action=\"store_true\")\n",
    "#parser.add_argument(\"-iam\", help='use iam dataset', action='store_true')\n",
    "# densenet hyperparam\n",
    "parser.add_argument(\"-nondensenet\", help=\"use noncustom (original) vanilla cnn\", action=\"store_true\")\n",
    "parser.add_argument(\"-growth_rate\", default=12, type=int, help='growth rate (k)')\n",
    "parser.add_argument(\"-layers_per_block\", default=18, type=int, help='number of layers per block')\n",
    "parser.add_argument(\"-total_blocks\", default=5, type=int, help='nuber of densenet blocks')\n",
    "parser.add_argument(\"-keep_prob\", default=1, type=float, help='keep probability in dropout')\n",
    "parser.add_argument(\"-reduction\", default=0.4, type=float, help='reduction factor in 1x1 conv in transition layers')\n",
    "parser.add_argument(\"-bc_mode\", default=True, type=bool, help=\"bottleneck and compresssion mode\")\n",
    "# rnn,  hyperparams\n",
    "parser.add_argument(\"-rnndim\", default=256, type=int, help='rnn dimenstionality') #256\n",
    "parser.add_argument(\"-rnnsteps\", default=32, type=int, help='number of desired time steps (image slices) to feed rnn')\n",
    "# img size\n",
    "parser.add_argument(\"-imgsize\", default=[128,32], type=int, nargs='+') #qyk default 128,32\n",
    "# testset crop\n",
    "#parser.add_argument(\"-crop_r1\", default=3, type=int)\n",
    "#parser.add_argument(\"-crop_r2\", default=28, type=int)\n",
    "#parser.add_argument(\"-crop_c1\", default=10, type=int)\n",
    "#parser.add_argument(\"-crop_c2\", default=115, type=int)\n",
    "# filepaths\n",
    "#parser.add_argument(\"-dataroot\", default='/root/datasets', type=str)\n",
    "parser.add_argument(\"-ckptroot\", default='/root/ckpt', type=str)\n",
    "#parser.add_argument(\"-urlTransferFrom\", default=None, type=str)\n",
    "\n",
    "args = parser.parse_known_args()[0]\n",
    "home = os.environ['HOME']\n",
    "name = args.name\n",
    "ckptroot = join(home, 'ckpt')\n",
    "args.ckptpath = join(ckptroot, name)\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = args.gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/root/WordSegmentationRecognitionPipeline/src/debug/'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.debug_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Image Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image_paths=glob(args.image_root+'**.jpg')\n",
    "image_paths=glob(args.image_root+'sentence.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initiate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading EAST text detector...\n"
     ]
    }
   ],
   "source": [
    "model_east=east_cv2(args,experiment=experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build Densenet4htr model with 5 blocks, 9 bottleneck layers and 9 composite layers each.\n",
      "Depth: 96\n",
      "Reduction at transition layers: 0.4\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "densenet feature extractor graph built in (sec): 7.612532138824463\n",
      "Total training params: 0.5M\n",
      "shape of cnn output: [None, 32, 1, 178]\n",
      "WARNING:tensorflow:From /root/WordSegmentationRecognitionPipeline/src/recognition/Model.py:102: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From /root/WordSegmentationRecognitionPipeline/src/recognition/Model.py:105: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From /root/WordSegmentationRecognitionPipeline/src/recognition/Model.py:110: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn.py:443: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET ERROR: Failed to extract parameters from Estimator.init()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.5.2 (default, Nov 12 2018, 13:43:14) \n",
      "[GCC 5.4.0 20160609]\n",
      "Tensorflow: 1.12.0-rc0\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:1557: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from /root/ckpt/dense_128_32_noartifact_beamsearch_5_datasets/model-35\n",
      "Init with stored values from /root/ckpt/dense_128_32_noartifact_beamsearch_5_datasets/model-35\n"
     ]
    }
   ],
   "source": [
    "decoderType = DecoderType.BestPath\n",
    "if args.beamsearch:\n",
    "    decoderType = DecoderType.BeamSearch\n",
    "elif args.wordbeamsearch:\n",
    "    decoderType = DecoderType.WordBeamSearch\n",
    "\n",
    "model_recg = Model(args, open(join(args.ckptpath, 'charList.txt')).read(), decoderType, mustRestore=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CV2 EAST Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] text detection took 2.065869 seconds\n"
     ]
    }
   ],
   "source": [
    "images,boundingboxes=model_east.crop(image_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merged_boxes=non_max_suppression_merge(boundingboxes, probs=None, overlapThresh=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "print(len(images))\n",
    "print(len(merged_boxes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig=cv2.imread(image_paths[0])\n",
    "images_rlt=[]\n",
    "boundingbox_rlt=[]        \n",
    "# loop over the bounding boxes\n",
    "for (startX, startY, endX, endY) in merged_boxes:\n",
    "    # crop\n",
    "    img=orig[startY:endY+1,startX:endX+1]  \n",
    "    # deal with vertical alignment, strong assumption\n",
    "    if endY-startY>1.2*(endX-startX):\n",
    "        # draw the bounding box on the image\n",
    "        \n",
    "        img=img.transpose((1,0,2))\n",
    "        \n",
    "        if startX>0.9*orig.shape[1]:\n",
    "            img=np.flip(img,axis=1)\n",
    "          \n",
    "    # grey and size normalize, compatible to recognition\n",
    "    img=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img=cv2.resize(img,(args.imgsize[0],args.imgsize[1]),interpolation=cv2.INTER_CUBIC)\n",
    "    img=cv2.transpose(img)\n",
    "            \n",
    "    images_rlt.append(img)\n",
    "    boundingbox_rlt.append((startX,startY,endX,endY)) \n",
    "    if experiment!=None:\n",
    "        cv2.rectangle(orig, (startX, startY), (endX, endY), (0, 255, 0), 2)\n",
    "        \n",
    "if experiment!=None:    \n",
    "    imageFile=args.debug_folder+'east_test_merged_cropped.jpg'\n",
    "    cv2.imwrite(imageFile,orig)\n",
    "    experiment.log_image(imageFile)\n",
    "    time.sleep(.2)\n",
    "    os.remove(imageFile)        \n",
    "\n",
    "images=images_rlt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recognition "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assumption: \n",
    "1. The number of words is less than 500, let's try to predict them in one batch\n",
    "2. The images in images list variable are all on word level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "recognizeds=model_recg.inferBatch(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1c21afd2b0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#log experiment\n",
    "if experiment !=None:\n",
    "    result_sets=zip(images,recognizeds)\n",
    "    for idx, (image, label) in enumerate(result_sets):\n",
    "        text = '['+str(idx)+']: '+label\n",
    "        log_image(experiment, image, text, '', args.debug_folder, counter='', epoch='')\n",
    "        #counter += 1 # previous batch.imgs[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['doine', 'lelle', 'haw', 'y9r1', 'oire', 'hank', 'fohe', 'y9u', 'oin']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recognizeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
