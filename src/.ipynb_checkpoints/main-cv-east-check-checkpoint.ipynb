{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages and Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: old comet version (1.0.44) detected. current: 1.0.56 please update your comet lib with command: `pip install --no-cache-dir --upgrade comet_ml`\n",
      "COMET WARNING: Failing to collect the installed os packages\n",
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/yikeqicn/ocr-pipeline/ec505155b9584d6fbe49f135a73215ca\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# experiment (optional)\n",
    "from comet_ml import Experiment\n",
    "experiment = Experiment(api_key=\"YkPEmantOag1R1VOJmXz11hmt\", parse_args=False, project_name='ocr_pipeline')\n",
    "experiment.set_name('pipeline_cv_east_handwriten_twolines_crop_merged')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import time\n",
    "import cv2\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from glob import glob\n",
    "from os.path import join, basename, dirname\n",
    "from east.model import *\n",
    "from recognition.Model import Model, DecoderType\n",
    "from recognition.utils import log_image\n",
    "from wordsegmentation.WordSegmentation import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Public Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['-image_root', '--image_root'], dest='image_root', nargs=None, const=None, default='/root/WordSegmentationRecognitionPipeline/src/Inputs/', type=<class 'str'>, choices=None, help='path to input image root', metavar=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "#general:\n",
    "parser.add_argument(\"-debug_folder\", \"--debug_folder\", type=str,default='/root/WordSegmentationRecognitionPipeline/src/debug/',help=\"path to debug folder\")\n",
    "\n",
    "# EAST model:\n",
    "## parameter\n",
    "parser.add_argument(\"-east_w\", \"--east_width\", type=int, default=1920,help=\" east model resized image width (should be multiple of 32)\")\n",
    "parser.add_argument(\"-east_e\", \"--east_height\", type=int, default=1920,help=\"east model resized image height (should be multiple of 32)\")\n",
    "parser.add_argument(\"-mini_conf\", \"--mini_conf\", type=int, default=0.5,help=\"mini_confidence for crop\")\n",
    "\n",
    "## ckpt\n",
    "parser.add_argument(\"-east\", \"--east\", type=str,default='/root/WordSegmentationRecognitionPipeline/src/east/frozen_east_text_detection.pb',help=\"path to input EAST text detector\")\n",
    "## input image root\n",
    "parser.add_argument(\"-image_root\", \"--image_root\", type=str,default='/root/WordSegmentationRecognitionPipeline/src/Inputs/',help=\"path to input image root\")\n",
    "\n",
    "# Recognition model:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recognition Model\n",
    "# basic operations\n",
    "parser.add_argument(\"-name\", default='dense_128_32_noartifact_beamsearch_5_datasets', type=str, help=\"name of the log\")\n",
    "parser.add_argument(\"-gpu\", default='-1', type=str, help=\"gpu numbers\")\n",
    "#parser.add_argument(\"-train\", help=\"train the NN\", action=\"store_true\")\n",
    "#parser.add_argument(\"-validate\", help=\"validate the NN\", action=\"store_true\")\n",
    "parser.add_argument(\"-transfer\", action=\"store_true\")\n",
    "#actually not effective:\n",
    "parser.add_argument(\"-batchesTrained\", default=0, type=int, help='number of batches already trained (for lr schedule)') \n",
    "# beam search\n",
    "parser.add_argument(\"-beamsearch\", help=\"use beam search instead of best path decoding\",default=True, action=\"store_true\")\n",
    "parser.add_argument(\"-wordbeamsearch\", help=\"use word beam search instead of best path decoding\", action=\"store_true\")\n",
    "# training hyperparam\n",
    "parser.add_argument(\"-batchsize\", default=50, type=int, help='batch size') # actually not effective in infrerence\n",
    "parser.add_argument(\"-lrInit\", default=1e-2, type=float, help='initial learning rate') # actually not effective\n",
    "parser.add_argument(\"-optimizer\", default='rmsprop', help=\"adam, rmsprop, momentum\") # actually not effective\n",
    "parser.add_argument(\"-wdec\", default=1e-4, type=float, help='weight decay') # acctually not effective\n",
    "#parser.add_argument(\"-lrDrop1\", default=10, type=int, help='step to drop lr by 10 first time')\n",
    "#parser.add_argument(\"-lrDrop2\", default=1000, type=int, help='step to drop lr by 10 sexond time')\n",
    "#parser.add_argument(\"-epochEnd\", default=40, type=int, help='end after this many epochs')\n",
    "# trainset hyperparam\n",
    "#parser.add_argument(\"-noncustom\", help=\"noncustom (original) augmentation technique\", action=\"store_true\")\n",
    "#parser.add_argument(\"-noartifact\", help=\"dont insert artifcats\", action=\"store_true\")\n",
    "#parser.add_argument(\"-iam\", help='use iam dataset', action='store_true')\n",
    "# densenet hyperparam\n",
    "parser.add_argument(\"-nondensenet\", help=\"use noncustom (original) vanilla cnn\", action=\"store_true\")\n",
    "parser.add_argument(\"-growth_rate\", default=12, type=int, help='growth rate (k)')\n",
    "parser.add_argument(\"-layers_per_block\", default=18, type=int, help='number of layers per block')\n",
    "parser.add_argument(\"-total_blocks\", default=5, type=int, help='nuber of densenet blocks')\n",
    "parser.add_argument(\"-keep_prob\", default=1, type=float, help='keep probability in dropout')\n",
    "parser.add_argument(\"-reduction\", default=0.4, type=float, help='reduction factor in 1x1 conv in transition layers')\n",
    "parser.add_argument(\"-bc_mode\", default=True, type=bool, help=\"bottleneck and compresssion mode\")\n",
    "# rnn,  hyperparams\n",
    "parser.add_argument(\"-rnndim\", default=256, type=int, help='rnn dimenstionality') #256\n",
    "parser.add_argument(\"-rnnsteps\", default=32, type=int, help='number of desired time steps (image slices) to feed rnn')\n",
    "# img size\n",
    "parser.add_argument(\"-imgsize\", default=[128,32], type=int, nargs='+') #qyk default 128,32\n",
    "# testset crop\n",
    "#parser.add_argument(\"-crop_r1\", default=3, type=int)\n",
    "#parser.add_argument(\"-crop_r2\", default=28, type=int)\n",
    "#parser.add_argument(\"-crop_c1\", default=10, type=int)\n",
    "#parser.add_argument(\"-crop_c2\", default=115, type=int)\n",
    "# filepaths\n",
    "#parser.add_argument(\"-dataroot\", default='/root/datasets', type=str)\n",
    "parser.add_argument(\"-ckptroot\", default='/root/ckpt', type=str)\n",
    "#parser.add_argument(\"-urlTransferFrom\", default=None, type=str)\n",
    "\n",
    "args = parser.parse_known_args()[0]\n",
    "home = os.environ['HOME']\n",
    "name = args.name\n",
    "ckptroot = join(home, 'ckpt')\n",
    "args.ckptpath = join(ckptroot, name)\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = args.gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/root/WordSegmentationRecognitionPipeline/src/debug/'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.debug_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Image Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#image_paths=glob(args.image_root+'**.jpg')\n",
    "image_paths=glob(args.image_root+'twolines.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initiate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading EAST text detector...\n"
     ]
    }
   ],
   "source": [
    "model_east=east_cv2(args,experiment=experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build Densenet4htr model with 5 blocks, 9 bottleneck layers and 9 composite layers each.\n",
      "Depth: 96\n",
      "Reduction at transition layers: 0.4\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "densenet feature extractor graph built in (sec): 7.600031614303589\n",
      "Total training params: 0.5M\n",
      "shape of cnn output: [None, 32, 1, 178]\n",
      "WARNING:tensorflow:From /root/WordSegmentationRecognitionPipeline/src/recognition/Model.py:102: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From /root/WordSegmentationRecognitionPipeline/src/recognition/Model.py:105: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From /root/WordSegmentationRecognitionPipeline/src/recognition/Model.py:110: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn.py:443: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET ERROR: Failed to extract parameters from Estimator.init()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.5.2 (default, Nov 12 2018, 13:43:14) \n",
      "[GCC 5.4.0 20160609]\n",
      "Tensorflow: 1.12.0-rc0\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:1557: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from /root/ckpt/dense_128_32_noartifact_beamsearch_5_datasets/model-35\n",
      "Init with stored values from /root/ckpt/dense_128_32_noartifact_beamsearch_5_datasets/model-35\n"
     ]
    }
   ],
   "source": [
    "decoderType = DecoderType.BestPath\n",
    "if args.beamsearch:\n",
    "    decoderType = DecoderType.BeamSearch\n",
    "elif args.wordbeamsearch:\n",
    "    decoderType = DecoderType.WordBeamSearch\n",
    "\n",
    "model_recg = Model(args, open(join(args.ckptpath, 'charList.txt')).read(), decoderType, mustRestore=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CV2 EAST Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/root/WordSegmentationRecognitionPipeline/src/Inputs/twolines.jpg'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_paths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] text detection took 2.212843 seconds\n"
     ]
    }
   ],
   "source": [
    "images,boundingboxes=model_east.crop(image_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merged_boxes=non_max_suppression_merge(boundingboxes, probs=None, overlapThresh=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "print(len(images))\n",
    "print(len(merged_boxes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig=cv2.imread(image_paths[0])\n",
    "images_rlt=[]\n",
    "boundingbox_rlt=[]        \n",
    "# loop over the bounding boxes\n",
    "for (startX, startY, endX, endY) in merged_boxes:\n",
    "    # crop\n",
    "    img=orig[startY:endY+1,startX:endX+1]  \n",
    "    # deal with vertical alignment, strong assumption\n",
    "    if endY-startY>1.2*(endX-startX):\n",
    "        # draw the bounding box on the image\n",
    "        \n",
    "        img=img.transpose((1,0,2))\n",
    "        \n",
    "        if startX>0.9*orig.shape[1]:\n",
    "            img=np.flip(img,axis=1)\n",
    "          \n",
    "    # grey and size normalize, compatible to recognition\n",
    "    img=cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img=cv2.resize(img,(args.imgsize[0],args.imgsize[1]),interpolation=cv2.INTER_CUBIC)\n",
    "    img=cv2.transpose(img)\n",
    "            \n",
    "    images_rlt.append(img)\n",
    "    boundingbox_rlt.append((startX,startY,endX,endY)) \n",
    "    if experiment!=None:\n",
    "        cv2.rectangle(orig, (startX, startY), (endX, endY), (0, 255, 0), 2)\n",
    "        \n",
    "if experiment!=None:    \n",
    "    imageFile=args.debug_folder+'east_test_merged_cropped.jpg'\n",
    "    cv2.imwrite(imageFile,orig)\n",
    "    experiment.log_image(imageFile)\n",
    "    time.sleep(.2)\n",
    "    os.remove(imageFile)        \n",
    "\n",
    "images=images_rlt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recognition "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assumption: \n",
    "1. The number of words is less than 500, let's try to predict them in one batch\n",
    "2. The images in images list variable are all on word level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "recognizeds=model_recg.inferBatch(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0356c26ba8>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#log experiment\n",
    "if experiment !=None:\n",
    "    result_sets=zip(images,recognizeds)\n",
    "    for idx, (image, label) in enumerate(result_sets):\n",
    "        text = '['+str(idx)+']: '+label\n",
    "        log_image(experiment, image, text, '', args.debug_folder, counter='', epoch='')\n",
    "        #counter += 1 # previous batch.imgs[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Angeles', 'ork', 'W', 'to', 'r0m', 'be', 'the', 'ot']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recognizeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
