{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages and Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: old comet version (1.0.44) detected. current: 1.0.51 please update your comet lib with command: `pip install --no-cache-dir --upgrade comet_ml`\n",
      "COMET WARNING: Failing to collect the installed os packages\n",
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/yikeqicn/ocr-pipeline/e28d1e5f28064ddc81b98d12188711b1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# experiment (optional)\n",
    "from comet_ml import Experiment\n",
    "experiment = Experiment(api_key=\"YkPEmantOag1R1VOJmXz11hmt\", parse_args=False, project_name='ocr_pipeline')\n",
    "experiment.set_name('pipeline_debug')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import time\n",
    "import cv2\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from glob import glob\n",
    "from os.path import join, basename, dirname\n",
    "from east.model import *\n",
    "from recognition.Model import Model, DecoderType\n",
    "from recognition.utils import log_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Public Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['-image_root', '--image_root'], dest='image_root', nargs=None, const=None, default='/root/yq/WordSegmentationRecognitionPipeline/src/Inputs/', type=<class 'str'>, choices=None, help='path to input image root', metavar=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "#general:\n",
    "parser.add_argument(\"-debug_folder\", \"--debug_folder\", type=str,default='/root/yq/WordSegmentationRecognitionPipeline/src/debug/',help=\"path to debug folder\")\n",
    "\n",
    "# EAST model:\n",
    "## parameter\n",
    "parser.add_argument(\"-east_w\", \"--east_width\", type=int, default=1920,help=\" east model resized image width (should be multiple of 32)\")\n",
    "parser.add_argument(\"-east_e\", \"--east_height\", type=int, default=1920,help=\"east model resized image height (should be multiple of 32)\")\n",
    "parser.add_argument(\"-mini_conf\", \"--mini_conf\", type=int, default=0.5,help=\"mini_confidence for crop\")\n",
    "\n",
    "## ckpt\n",
    "parser.add_argument(\"-east\", \"--east\", type=str,default='/root/yq/WordSegmentationRecognitionPipeline/src/east/frozen_east_text_detection.pb',help=\"path to input EAST text detector\")\n",
    "## input image root\n",
    "parser.add_argument(\"-image_root\", \"--image_root\", type=str,default='/root/yq/WordSegmentationRecognitionPipeline/src/Inputs/',help=\"path to input image root\")\n",
    "\n",
    "# Recognition model:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recognition Model\n",
    "# basic operations\n",
    "parser.add_argument(\"-name\", default='dense_128_32_noartifact_beamsearch_prt', type=str, help=\"name of the log\")\n",
    "parser.add_argument(\"-gpu\", default='-1', type=str, help=\"gpu numbers\")\n",
    "#parser.add_argument(\"-train\", help=\"train the NN\", action=\"store_true\")\n",
    "#parser.add_argument(\"-validate\", help=\"validate the NN\", action=\"store_true\")\n",
    "parser.add_argument(\"-transfer\", action=\"store_true\")\n",
    "#actually not effective:\n",
    "parser.add_argument(\"-batchesTrained\", default=0, type=int, help='number of batches already trained (for lr schedule)') \n",
    "# beam search\n",
    "parser.add_argument(\"-beamsearch\", help=\"use beam search instead of best path decoding\",default=True, action=\"store_true\")\n",
    "parser.add_argument(\"-wordbeamsearch\", help=\"use word beam search instead of best path decoding\", action=\"store_true\")\n",
    "# training hyperparam\n",
    "parser.add_argument(\"-batchsize\", default=50, type=int, help='batch size') # actually not effective in infrerence\n",
    "parser.add_argument(\"-lrInit\", default=1e-2, type=float, help='initial learning rate') # actually not effective\n",
    "parser.add_argument(\"-optimizer\", default='rmsprop', help=\"adam, rmsprop, momentum\") # actually not effective\n",
    "parser.add_argument(\"-wdec\", default=1e-4, type=float, help='weight decay') # acctually not effective\n",
    "#parser.add_argument(\"-lrDrop1\", default=10, type=int, help='step to drop lr by 10 first time')\n",
    "#parser.add_argument(\"-lrDrop2\", default=1000, type=int, help='step to drop lr by 10 sexond time')\n",
    "#parser.add_argument(\"-epochEnd\", default=40, type=int, help='end after this many epochs')\n",
    "# trainset hyperparam\n",
    "#parser.add_argument(\"-noncustom\", help=\"noncustom (original) augmentation technique\", action=\"store_true\")\n",
    "#parser.add_argument(\"-noartifact\", help=\"dont insert artifcats\", action=\"store_true\")\n",
    "#parser.add_argument(\"-iam\", help='use iam dataset', action='store_true')\n",
    "# densenet hyperparam\n",
    "parser.add_argument(\"-nondensenet\", help=\"use noncustom (original) vanilla cnn\", action=\"store_true\")\n",
    "parser.add_argument(\"-growth_rate\", default=12, type=int, help='growth rate (k)')\n",
    "parser.add_argument(\"-layers_per_block\", default=18, type=int, help='number of layers per block')\n",
    "parser.add_argument(\"-total_blocks\", default=5, type=int, help='nuber of densenet blocks')\n",
    "parser.add_argument(\"-keep_prob\", default=1, type=float, help='keep probability in dropout')\n",
    "parser.add_argument(\"-reduction\", default=0.4, type=float, help='reduction factor in 1x1 conv in transition layers')\n",
    "parser.add_argument(\"-bc_mode\", default=True, type=bool, help=\"bottleneck and compresssion mode\")\n",
    "# rnn,  hyperparams\n",
    "parser.add_argument(\"-rnndim\", default=256, type=int, help='rnn dimenstionality') #256\n",
    "parser.add_argument(\"-rnnsteps\", default=32, type=int, help='number of desired time steps (image slices) to feed rnn')\n",
    "# img size\n",
    "parser.add_argument(\"-imgsize\", default=[128,32], type=int, nargs='+') #qyk default 128,32\n",
    "# testset crop\n",
    "#parser.add_argument(\"-crop_r1\", default=3, type=int)\n",
    "#parser.add_argument(\"-crop_r2\", default=28, type=int)\n",
    "#parser.add_argument(\"-crop_c1\", default=10, type=int)\n",
    "#parser.add_argument(\"-crop_c2\", default=115, type=int)\n",
    "# filepaths\n",
    "#parser.add_argument(\"-dataroot\", default='/root/datasets', type=str)\n",
    "parser.add_argument(\"-ckptroot\", default='/root/ckpt', type=str)\n",
    "#parser.add_argument(\"-urlTransferFrom\", default=None, type=str)\n",
    "\n",
    "args = parser.parse_known_args()[0]\n",
    "home = os.environ['HOME']\n",
    "name = args.name\n",
    "ckptroot = join(home, 'ckpt')\n",
    "args.ckptpath = join(ckptroot, name)\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = args.gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(batchesTrained=0, batchsize=50, bc_mode=True, beamsearch=True, ckptpath='/root/ckpt/dense_128_32_noartifact_beamsearch_prt', ckptroot='/root/ckpt', debug_folder='/root/yq/WordSegmentationRecognitionPipeline/src/debug/', east='/root/yq/WordSegmentationRecognitionPipeline/src/east/frozen_east_text_detection.pb', east_height=1920, east_width=1920, gpu='-1', growth_rate=12, image_root='/root/yq/WordSegmentationRecognitionPipeline/src/Inputs/', imgsize=[128, 32], keep_prob=1, layers_per_block=18, lrInit=0.01, mini_conf=0.5, name='dense_128_32_noartifact_beamsearch_prt', nondensenet=False, optimizer='rmsprop', reduction=0.4, rnndim=256, rnnsteps=32, total_blocks=5, transfer=False, wdec=0.0001, wordbeamsearch=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Image Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths=glob(args.image_root+'**.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initiate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading EAST text detector...\n"
     ]
    }
   ],
   "source": [
    "model_east=east_cv2(args,experiment=experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build Densenet4htr model with 5 blocks, 9 bottleneck layers and 9 composite layers each.\n",
      "Depth: 96\n",
      "Reduction at transition layers: 0.4\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "densenet feature extractor graph built in (sec): 7.246107816696167\n",
      "Total training params: 0.5M\n",
      "shape of cnn output: [None, 32, 1, 178]\n",
      "WARNING:tensorflow:From /root/yq/WordSegmentationRecognitionPipeline/src/recognition/Model.py:102: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From /root/yq/WordSegmentationRecognitionPipeline/src/recognition/Model.py:105: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From /root/yq/WordSegmentationRecognitionPipeline/src/recognition/Model.py:110: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/rnn.py:443: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET ERROR: Failed to extract parameters from Estimator.init()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.5.2 (default, Nov 12 2018, 13:43:14) \n",
      "[GCC 5.4.0 20160609]\n",
      "Tensorflow: 1.12.0-rc0\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:1557: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from /root/ckpt/dense_128_32_noartifact_beamsearch_prt/model-37\n",
      "Init with stored values from /root/ckpt/dense_128_32_noartifact_beamsearch_prt/model-37\n"
     ]
    }
   ],
   "source": [
    "decoderType = DecoderType.BestPath\n",
    "if args.beamsearch:\n",
    "    decoderType = DecoderType.BeamSearch\n",
    "elif args.wordbeamsearch:\n",
    "    decoderType = DecoderType.WordBeamSearch\n",
    "\n",
    "model_recg = Model(args, open(join(args.ckptpath, 'charList.txt')).read(), decoderType, mustRestore=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CV2 EAST Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] text detection took 4.564350 seconds\n"
     ]
    }
   ],
   "source": [
    "images,boundingboxes=model_east.crop(image_paths[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recognition "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assumption: \n",
    "1. The number of words is less than 500, let's try to predict them in one batch\n",
    "2. The images in images list variable are all on word level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "recognizeds=model_recg.inferBatch(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#log experiment\n",
    "if experiment !=None:\n",
    "    result_sets=zip(images,recognizeds)\n",
    "    for idx, (image, label) in enumerate(result_sets):\n",
    "        text = '['+str(idx)+']: '+label\n",
    "        log_image(experiment, image, text, '', args.debug_folder, counter='', epoch='')\n",
    "        #counter += 1 # previous batch.imgs[i]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
